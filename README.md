# Event-Driven Data Processing Pipeline

[![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20ECS%20%7C%20ECR-FF9900?logo=amazon-aws&logoColor=white)](https://aws.amazon.com/)
[![Terraform](https://img.shields.io/badge/Terraform-Infrastructure-7B42BC?logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-CI%2FCD-2088FF?logo=github-actions&logoColor=white)](https://github.com/features/actions)

A production-ready, event-driven batch processing pipeline that reliably ingests raw data, processes it on schedule, and produces structured output artifacts for downstream consumers.

## ğŸ¯ Core Objectives

- **Decoupling** â€” Producers and consumers operate independently
- **Durability** â€” Reliable storage with retry and replay capabilities
- **Automation** â€” Infrastructure as Code for repeatability
- **Observability** â€” Comprehensive logging and monitoring
- **Security** â€” Least-privilege IAM and encryption at rest
- **Cost-Efficient** â€” Serverless architecture that scales with demand

## ğŸ—ï¸ Architecture

```
Data Sources â†’ S3 (Raw Data) â†’ EventBridge (Scheduler) â†’ ECS Fargate (Processing) â†’ S3 (Reports)
                    â†“                                            â†“
                Versioning                                CloudWatch Logs
```

### Components

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Storage** | Durable data lake for raw inputs and reports | Amazon S3 |
| **Orchestration** | Schedule-based or event-driven triggers | EventBridge |
| **Compute** | Containerized processing runtime | ECS Fargate |
| **Registry** | Container image storage | Amazon ECR |
| **Infrastructure** | Codified resource provisioning | Terraform |
| **CI/CD** | Automated build and deployment | GitHub Actions |
| **Monitoring** | Logging and observability | CloudWatch |

## ğŸš€ Data Flow

1. **Ingestion** â€” Raw files uploaded to `s3://bucket/raw-data/YYYY-MM-DD/`
2. **Trigger** â€” EventBridge invokes ECS task on schedule or event
3. **Processing** â€” Fargate container reads data, aggregates results
4. **Output** â€” Report written to `s3://bucket/reports/YYYY-MM-DD.json`
5. **Logging** â€” All operations logged to CloudWatch for audit and debugging

## ğŸ“‹ Prerequisites

- AWS Account with appropriate permissions
- Terraform >= 1.0
- Docker
- Python 3.11+
- GitHub repository for CI/CD

## ğŸ› ï¸ Setup

### 1. Infrastructure Provisioning

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

### 2. CI/CD Configuration

Configure GitHub Secrets:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_REGION`

### 3. Deploy Application

Push to main branch to trigger automated build and deployment:

```bash
git push origin main
```

## ğŸ” Security Features

- **IAM Roles** â€” Separate execution and task roles with least-privilege policies
- **Encryption** â€” S3 server-side encryption (SSE-S3)
- **Network Isolation** â€” VPC configuration with security groups
- **Image Scanning** â€” ECR vulnerability scanning on push
- **Secrets Management** â€” AWS Secrets Manager integration

## ğŸ“Š Monitoring & Observability

### CloudWatch Integration
- Container logs: `/ecs/assignment`
- Metrics: Task success/failure rates, duration, record counts
- Alarms: Task failures, processing delays

### Recommended Alarms
- Task stopped with non-zero exit code
- No reports generated for 24+ hours
- Processing duration exceeds threshold

## ğŸ”§ Operations

### Manual Task Execution

```bash
aws ecs run-task \
  --cluster <cluster-name> \
  --task-definition <task-def> \
  --launch-type FARGATE \
  --network-configuration "awsvpcConfiguration={subnets=[<subnet-id>],securityGroups=[<sg-id>]}" \
  --overrides '{"containerOverrides":[{"name":"processor","environment":[{"name":"RUN_DATE","value":"2025-01-15"}]}]}'
```

### Reprocessing Data

Set `RUN_DATE` environment variable to reprocess specific dates:

```bash
RUN_DATE=2025-01-15 ./scripts/reprocess.sh
```

## ğŸ“ˆ Scaling Patterns

| Pattern | Use Case | Implementation |
|---------|----------|----------------|
| **Vertical** | Larger files | Increase Fargate CPU/memory |
| **Horizontal** | High volume | Partition data, run parallel tasks |
| **Fan-out** | Complex workflows | SQS queue + worker fleet |

## ğŸ’° Cost Optimization

- S3 lifecycle policies for data retention
- Fargate task sizing matched to workload
- ECR image cleanup policies
- CloudWatch log retention policies
- Scheduled tasks run during off-peak hours

## ğŸ§ª Testing

```bash
# Unit tests
pytest tests/unit/

# Integration tests (requires localstack)
pytest tests/integration/

# End-to-end tests (dev environment)
./scripts/e2e-test.sh
```

## ğŸ”„ CI/CD Pipeline

1. **Build** â€” Docker image built on code push
2. **Scan** â€” Image scanned for vulnerabilities
3. **Push** â€” Image pushed to ECR with commit SHA tag
4. **Deploy** â€” Task definition updated (manual trigger)

## ğŸ“š Project Structure

```
.
â”œâ”€â”€ terraform/           # Infrastructure as Code
â”œâ”€â”€ src/                 # Application code
â”œâ”€â”€ .github/workflows/   # CI/CD pipelines
â”œâ”€â”€ tests/               # Test suites
â””â”€â”€ scripts/             # Operational scripts
```

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| Task fails to start | Check IAM execution role, ECR permissions |
| Permission denied on S3 | Verify task role has `s3:GetObject`, `s3:PutObject` |
| No logs in CloudWatch | Ensure task execution role has CloudWatch permissions |
| Image pull errors | Verify ECR repository policy, check image exists |

## ğŸš¦ Production Readiness Checklist

- [ ] Remote Terraform state with locking (S3 + DynamoDB)
- [ ] Multi-environment setup (dev/staging/prod)
- [ ] Automated testing in CI pipeline
- [ ] Comprehensive monitoring and alerting
- [ ] Disaster recovery and backup procedures
- [ ] Secrets managed via AWS Secrets Manager
- [ ] VPC endpoints for private S3/ECR access
- [ ] Blue-green deployment strategy


---

**Built with â¤ï¸ using AWS serverless technologies**
